{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0cbb3f5",
   "metadata": {},
   "source": [
    "#  <center> Analyse de Sentiments ‚Äì Approches Pratiques (VADER, ML, BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499bccc9",
   "metadata": {},
   "source": [
    "## üî∏ 1. Analyse lexicale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6470add3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnltk\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'nltk'"
     ]
    }
   ],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b378bc07",
   "metadata": {},
   "source": [
    "### avec SentiWordNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523ad64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Sentiwordnet*******\n",
      "Texte : I absolutely loved this movie!! üòç But the ending was disappointing.\n",
      "Scores : 0.75\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "#nltk.download('punkt')\n",
    "\n",
    "# Exemple\n",
    "texte = \"I absolutely loved this movie!! üòç But the ending was disappointing.\"\n",
    "\n",
    "tokens = nltk.word_tokenize(texte)\n",
    "sentiwordnet_score = 0\n",
    "for token in tokens:\n",
    "    # Rechercher le synset (ensemble de synonymes) pour chaque mot dans SentiWordNet\n",
    "    synsets = list(swn.senti_synsets(token))\n",
    "    if synsets:\n",
    "        sentiwordnet_score += synsets[0].pos_score() - synsets[0].neg_score()\n",
    "\n",
    "print(\"*******Sentiwordnet*******\")\n",
    "print(\"Texte :\", texte)\n",
    "print(\"Scores :\", sentiwordnet_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76198ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******SentiWordNet*******\n",
      "Texte :  I absolutely loved this movie!! üòç But the ending was disappointing.\n",
      "\n",
      "D√©tails des scores pour chaque mot :\n",
      "I: Positif = 0.0, N√©gatif = 0.0, Neutre = 1.0\n",
      "absolutely: Positif = 0.5, N√©gatif = 0.0, Neutre = 0.5\n",
      "loved: Positif = 0.5, N√©gatif = 0.0, Neutre = 0.5\n",
      "this: Positif = 0.0, N√©gatif = 0.0, Neutre = 1.0\n",
      "movie: Positif = 0.0, N√©gatif = 0.0, Neutre = 1.0\n",
      "!: Positif = 0.0, N√©gatif = 0.0, Neutre = 1.0\n",
      "üòç: Positif = 0.0, N√©gatif = 0.0, Neutre = 1.0\n",
      "But: Positif = 0.0, N√©gatif = 0.0, Neutre = 1.0\n",
      "the: Positif = 0.0, N√©gatif = 0.0, Neutre = 1.0\n",
      "ending: Positif = 0.0, N√©gatif = 0.0, Neutre = 1.0\n",
      "was: Positif = 0.0, N√©gatif = 0.0, Neutre = 1.0\n",
      "disappointing: Positif = 0.0, N√©gatif = 0.25, Neutre = 0.75\n",
      ".: Positif = 0.0, N√©gatif = 0.0, Neutre = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Tokenisation du texte\n",
    "tokens = nltk.word_tokenize(texte)\n",
    "\n",
    "# D√©tail des affectations de score pour chaque mot\n",
    "scores_mots = {}\n",
    "\n",
    "for token in tokens:\n",
    "    synsets = list(swn.senti_synsets(token))\n",
    "    if synsets:\n",
    "        # Utiliser le premier synset de chaque mot pour obtenir un score\n",
    "        synset = synsets[0]\n",
    "        pos_score = synset.pos_score()\n",
    "        neg_score = synset.neg_score()\n",
    "        obj_score = synset.obj_score()  # Le score neutre\n",
    "\n",
    "        # Ajouter les scores dans le dictionnaire\n",
    "        scores_mots[token] = {\n",
    "            'pos_score': pos_score,\n",
    "            'neg_score': neg_score,\n",
    "            'obj_score': obj_score,\n",
    "        }\n",
    "    else:\n",
    "        # Si aucun synset trouv√©, ajouter un score neutre par d√©faut\n",
    "        scores_mots[token] = {\n",
    "            'pos_score': 0.0,\n",
    "            'neg_score': 0.0,\n",
    "            'obj_score': 1.0,  # neutre\n",
    "        }\n",
    "\n",
    "# Affichage des r√©sultats\n",
    "print(\"*******SentiWordNet*******\")\n",
    "print(\"Texte : \", texte)\n",
    "\n",
    "print(\"\\nD√©tails des scores pour chaque mot :\")\n",
    "for mot, scores in scores_mots.items():\n",
    "    print(f\"{mot}: Positif = {scores['pos_score']}, N√©gatif = {scores['neg_score']}, Neutre = {scores['obj_score']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbc218c",
   "metadata": {},
   "source": [
    "### avec Afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76fa351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Afinn*******\n",
      "Texte :  I absolutely loved this movie!! üòç But the ending was disappointing.\n",
      "Afinn Score :  1.0\n"
     ]
    }
   ],
   "source": [
    "from afinn import Afinn\n",
    "\n",
    "# Initialisation de l'analyseur Afinn\n",
    "afinn = Afinn()\n",
    "\n",
    "# Exemple de texte\n",
    "texte = \"I absolutely loved this movie!! üòç But the ending was disappointing.\"\n",
    "\n",
    "# Afinn - Analyse de sentiment\n",
    "afinn_score = afinn.score(texte)\n",
    "\n",
    "# R√©sultats\n",
    "print(\"*******Afinn*******\")\n",
    "print(\"Texte : \", texte)\n",
    "print(\"Afinn Score : \", afinn_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6685f549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Afinn*******\n",
      "\n",
      "D√©tails des scores pour chaque mot :\n",
      "I: 0.0\n",
      "absolutely: 0.0\n",
      "loved: 3.0\n",
      "this: 0.0\n",
      "movie!!: 0.0\n",
      "üòç: 0.0\n",
      "But: 0.0\n",
      "the: 0.0\n",
      "ending: 0.0\n",
      "was: 0.0\n",
      "disappointing.: -2.0\n"
     ]
    }
   ],
   "source": [
    "# D√©couper le texte en mots (tokenization)\n",
    "mots = texte.split()\n",
    "\n",
    "# D√©tail des affectations de score pour chaque mot\n",
    "scores_mots = {mot: afinn.score(mot) for mot in mots}\n",
    "\n",
    "# R√©sultats\n",
    "print(\"*******Afinn*******\")\n",
    "print(\"\\nD√©tails des scores pour chaque mot :\")\n",
    "\n",
    "for mot, score in scores_mots.items():\n",
    "    print(f\"{mot}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0faf08",
   "metadata": {},
   "source": [
    "### avec VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be711f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Vader*******\n",
      "Texte : I absolutely loved this movie!! üòç But the ending was disappointing.\n",
      "Scores : {'neg': 0.337, 'neu': 0.483, 'pos': 0.179, 'compound': -0.5086}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\INPT\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Cr√©ation de l'analyseur\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Exemple\n",
    "texte = \"I absolutely loved this movie!! üòç But the ending was disappointing.\"\n",
    "score = analyzer.polarity_scores(texte)\n",
    "print(\"*******Vader*******\")\n",
    "print(\"Texte :\", texte)\n",
    "print(\"Scores :\", score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e631e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******VADER*******\n",
      "\n",
      "D√©tails des scores pour chaque mot :\n",
      "I: {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound': 0.0}\n",
      "absolutely: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "loved: {'neg': 0.0, 'neu': 0.0, 'pos': 1.0, 'compound': 0.5994}\n",
      "this: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "movie!!: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "üòç: {'neg': 0.0, 'neu': 0.0, 'pos': 0.0, 'compound': 0.0}\n",
      "But: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "the: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "ending: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "was: {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "disappointing.: {'neg': 1.0, 'neu': 0.0, 'pos': 0.0, 'compound': -0.4939}\n"
     ]
    }
   ],
   "source": [
    "# Tokenisation du texte (division du texte en mots)\n",
    "mots = texte.split()\n",
    "\n",
    "# D√©tail des affectations de score pour chaque mot\n",
    "scores_mots = {}\n",
    "\n",
    "for mot in mots:\n",
    "    # On analyse chaque mot individuellement en l'enfermant dans une phrase\n",
    "    score = analyzer.polarity_scores(mot)\n",
    "    scores_mots[mot] = score\n",
    "\n",
    "\n",
    "# Affichage des r√©sultats\n",
    "print(\"*******VADER*******\")\n",
    "print(\"\\nD√©tails des scores pour chaque mot :\")\n",
    "for mot, score in scores_mots.items():\n",
    "    print(f\"{mot}: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2883ff8d",
   "metadata": {},
   "source": [
    "## üî∏ 2. Classification supervis√©e (TF-IDF + Logistic Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11dc88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  precision    recall  f1-score   support\n",
      "\n",
      "rec.sport.hockey       0.99      0.93      0.96       125\n",
      "       sci.space       0.93      0.99      0.96       114\n",
      "\n",
      "        accuracy                           0.96       239\n",
      "       macro avg       0.96      0.96      0.96       239\n",
      "    weighted avg       0.96      0.96      0.96       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Chargement d‚Äôun jeu de donn√©es simple (binary classification)\n",
    "categories = ['rec.sport.hockey', 'sci.space']\n",
    "data = fetch_20newsgroups(subset='train', categories=categories, remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Pr√©paration\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.2, random_state=42)\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Mod√®le\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_vec, y_train)\n",
    "y_pred = clf.predict(X_test_vec)\n",
    "\n",
    "# R√©sultats\n",
    "print(classification_report(y_test, y_pred, target_names=categories))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985e850c",
   "metadata": {},
   "source": [
    "## üî∏ 3. M√©thode neuronale (BERT avec Transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c5fa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ADAMA\\Desktop\\Sentiment analysis\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "c:\\Users\\ADAMA\\Desktop\\Sentiment analysis\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ADAMA\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte : I love the new design of your website! R√©sultat : {'label': 'POSITIVE', 'score': 0.9998718500137329}\n",
      "\n",
      "Texte : This product is terrible and I want a refund. R√©sultat : {'label': 'NEGATIVE', 'score': 0.9997045397758484}\n",
      "\n",
      "Texte : The plot was boring, but the cinematography was stunning. R√©sultat : {'label': 'POSITIVE', 'score': 0.9996780157089233}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!pip install transformers --quiet\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Pipeline d‚Äôanalyse de sentiments\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "\n",
    "# Exemple\n",
    "texts = [\n",
    "    \"I love the new design of your website!\",\n",
    "    \"This product is terrible and I want a refund.\",\n",
    "    \"The plot was boring, but the cinematography was stunning.\"\n",
    "]\n",
    "\n",
    "results = classifier(texts)\n",
    "for text, result in zip(texts, results):\n",
    "    print(f\"Texte : {text} R√©sultat : {result}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c98e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "c:\\Users\\ADAMA\\Desktop\\Sentiment analysis\\env\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ADAMA\\.cache\\huggingface\\hub\\models--cardiffnlp--twitter-roberta-base-sentiment. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte :  I absolutely loved this movie!! üòç But the ending was disappointing.\n",
      "R√©sultats de l'analyse de sentiment :  [{'label': 'LABEL_2', 'score': 0.9190811514854431}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialisation du pipeline pour l'analyse de sentiment avec RoBERTa\n",
    "analyse_sentiment = pipeline(\"sentiment-analysis\", model=\"cardiffnlp/twitter-roberta-base-sentiment\")\n",
    "\n",
    "# Exemple de texte\n",
    "texte = \"I absolutely loved this movie!! üòç But the ending was disappointing.\"\n",
    "\n",
    "# Analyse du sentiment\n",
    "resultat = analyse_sentiment(texte)\n",
    "\n",
    "# Affichage des r√©sultats\n",
    "print(\"Texte : \", texte)\n",
    "print(\"R√©sultats de l'analyse de sentiment : \", resultat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48ac06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
